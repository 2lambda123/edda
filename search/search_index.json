{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Edda \u00b6 Introduction \u00b6 Operating in the Cloud has its challenges, and one of those challenges is that nothing is static. Virtual host instances are constantly coming and going, IP addresses can get reused by different applications, and firewalls suddenly appear as security configurations are updated. At Netflix we needed something to help us keep track of our ever-shifting environment within Amazon Web Services (AWS). Our solution is Edda. What is Edda? \u00b6 Edda is a service that polls your AWS resources via AWS APIs and records the results. It allows you to quickly search through your resources and shows you how they have changed over time. Previously this project was known within Netflix as Entrypoints (and mentioned in some blog posts), but the name was changed as the scope of the project grew. Edda, which means \"a tale of Norse mythology\", seemed appropriate for the new name, as our application records the tales of Asgard . Why Did We Create Edda? \u00b6 Dynamic Querying \u00b6 At Netflix we need to be able to quickly query and analyze our AWS resources with widely varying search criteria. For instance, if we see a host with an EC2 hostname that is causing problems on one of our API servers then we need to find out what that host is and what team is responsible, Edda allows us to do this. The APIs AWS provides are fast and efficient but limited in their querying ability. There is no way to find an instance by the hostname, or find all instances in a specific Availability Zone without first fetching all the instances and iterating through them. With Edda's REST APIs we can use matrix arguments to find the resources that we are looking for. Furthermore, we can trim out unnecessary data in the responses with Field Selectors . History and Changes \u00b6 When trying to analyze causes and impacts of outages we have found the historical data stored in Edda to be very valuable. Currently AWS does not provide APIs that allow you to see the history of your resources, but Edda records each AWS resource as versioned documents that can be recalled via the REST API . The \"current state\" is stored in memory, which allows for quick access. Previous resource states and expired resources are stored in MongoDB (by default), which allows for efficient retrieval. Not only can you see how resources looked in the past, but you can also get unified diff output quickly and see all the changes a resource has gone through. High-Level Architecture \u00b6 Edda is a Scala application that can both run on a single instance or scale up to many instances running behind a load-balancer for high availability. The data store that Edda currently supports is MongoDB, which is also versatile enough to run on either a single instance along with the Edda service, or be grown to include large replication sets. When running as a cluster, Edda will automatically select a leader which then does all the AWS polling (by default every 60 seconds) and persists the data. The other secondary servers will be refreshing their in-memory records (by default every 30 seconds) and handling REST requests. Currently only MongoDB is supported for the persistence layer, but we are analyzing alternatives. MongoDB supports JSON documents and allows for advanced query options, both of which are necessary for Edda. However, as our previous blogs have indicated, Netflix is heavily invested in Cassandra. We are therefore looking at some options for advance query services that can work in conjunction with Cassandra. Edda was designed to allow for easily implementing custom crawlers to track collections of resources other than those of AWS. Configuration \u00b6 There are many configuration options for Edda. It can be configured to poll a single AWS region (as we run it here) or to poll multiple regions. If you have multiple AWS accounts (i.e. test and prod), Edda can be configured to poll both from the same instance. Edda currently polls 15 different resource types within AWS. Each collection can be individually enabled or disabled. Additionally, crawl frequency and cache refresh rates can all be tweaked.","title":"Edda"},{"location":"#edda","text":"","title":"Edda"},{"location":"#introduction","text":"Operating in the Cloud has its challenges, and one of those challenges is that nothing is static. Virtual host instances are constantly coming and going, IP addresses can get reused by different applications, and firewalls suddenly appear as security configurations are updated. At Netflix we needed something to help us keep track of our ever-shifting environment within Amazon Web Services (AWS). Our solution is Edda.","title":"Introduction"},{"location":"#what-is-edda","text":"Edda is a service that polls your AWS resources via AWS APIs and records the results. It allows you to quickly search through your resources and shows you how they have changed over time. Previously this project was known within Netflix as Entrypoints (and mentioned in some blog posts), but the name was changed as the scope of the project grew. Edda, which means \"a tale of Norse mythology\", seemed appropriate for the new name, as our application records the tales of Asgard .","title":"What is Edda?"},{"location":"#why-did-we-create-edda","text":"","title":"Why Did We Create Edda?"},{"location":"#dynamic-querying","text":"At Netflix we need to be able to quickly query and analyze our AWS resources with widely varying search criteria. For instance, if we see a host with an EC2 hostname that is causing problems on one of our API servers then we need to find out what that host is and what team is responsible, Edda allows us to do this. The APIs AWS provides are fast and efficient but limited in their querying ability. There is no way to find an instance by the hostname, or find all instances in a specific Availability Zone without first fetching all the instances and iterating through them. With Edda's REST APIs we can use matrix arguments to find the resources that we are looking for. Furthermore, we can trim out unnecessary data in the responses with Field Selectors .","title":"Dynamic Querying"},{"location":"#history-and-changes","text":"When trying to analyze causes and impacts of outages we have found the historical data stored in Edda to be very valuable. Currently AWS does not provide APIs that allow you to see the history of your resources, but Edda records each AWS resource as versioned documents that can be recalled via the REST API . The \"current state\" is stored in memory, which allows for quick access. Previous resource states and expired resources are stored in MongoDB (by default), which allows for efficient retrieval. Not only can you see how resources looked in the past, but you can also get unified diff output quickly and see all the changes a resource has gone through.","title":"History and Changes"},{"location":"#high-level-architecture","text":"Edda is a Scala application that can both run on a single instance or scale up to many instances running behind a load-balancer for high availability. The data store that Edda currently supports is MongoDB, which is also versatile enough to run on either a single instance along with the Edda service, or be grown to include large replication sets. When running as a cluster, Edda will automatically select a leader which then does all the AWS polling (by default every 60 seconds) and persists the data. The other secondary servers will be refreshing their in-memory records (by default every 30 seconds) and handling REST requests. Currently only MongoDB is supported for the persistence layer, but we are analyzing alternatives. MongoDB supports JSON documents and allows for advanced query options, both of which are necessary for Edda. However, as our previous blogs have indicated, Netflix is heavily invested in Cassandra. We are therefore looking at some options for advance query services that can work in conjunction with Cassandra. Edda was designed to allow for easily implementing custom crawlers to track collections of resources other than those of AWS.","title":"High-Level Architecture"},{"location":"#configuration","text":"There are many configuration options for Edda. It can be configured to poll a single AWS region (as we run it here) or to poll multiple regions. If you have multiple AWS accounts (i.e. test and prod), Edda can be configured to poll both from the same instance. Edda currently polls 15 different resource types within AWS. Each collection can be individually enabled or disabled. Additionally, crawl frequency and cache refresh rates can all be tweaked.","title":"Configuration"},{"location":"aws-permissions/","text":"Example IAM Role Policy \u00b6 { \"Statement\" : [{ \"Action\" : [ \"autoscaling:DescribeAutoScalingGroups\" , \"autoscaling:DescribeLaunchConfigurations\" , \"autoscaling:DescribePolicies\" , \"cloudwatch:DescribeAlarms\" , \"ec2:DescribeAddresses\" , \"ec2:DescribeImages\" , \"ec2:DescribeInstances\" , \"ec2:DescribeReservedInstances\" , \"ec2:DescribeSecurityGroups\" , \"ec2:DescribeSnapshots\" , \"ec2:DescribeTags\" , \"ec2:DescribeVolumes\" , \"elasticloadbalancing:DescribeInstanceHealth\" , \"elasticloadbalancing:DescribeLoadBalancers\" , \"iam:ListAccessKeys\" , \"iam:ListGroupPolicies\" , \"iam:ListGroups\" , \"iam:ListGroupsForUser\" , \"iam:ListRoles\" , \"iam:ListUserPolicies\" , \"iam:ListUsers\" , \"iam:ListVirtualMFADevices\" , \"s3:ListBucket\" , \"s3:ListAllMyBuckets\" , \"route53:ListHostedZones\" , \"route53:ListResourceRecordSets\" , \"sqs:GetQueueAttributes\" , \"sqs:ListQueues\" , \"rds:DescribeDBInstances\" ], \"Effect\" : \"Allow\" , \"Resource\" : \"*\" }] }","title":"AWS Permissions"},{"location":"aws-permissions/#example-iam-role-policy","text":"{ \"Statement\" : [{ \"Action\" : [ \"autoscaling:DescribeAutoScalingGroups\" , \"autoscaling:DescribeLaunchConfigurations\" , \"autoscaling:DescribePolicies\" , \"cloudwatch:DescribeAlarms\" , \"ec2:DescribeAddresses\" , \"ec2:DescribeImages\" , \"ec2:DescribeInstances\" , \"ec2:DescribeReservedInstances\" , \"ec2:DescribeSecurityGroups\" , \"ec2:DescribeSnapshots\" , \"ec2:DescribeTags\" , \"ec2:DescribeVolumes\" , \"elasticloadbalancing:DescribeInstanceHealth\" , \"elasticloadbalancing:DescribeLoadBalancers\" , \"iam:ListAccessKeys\" , \"iam:ListGroupPolicies\" , \"iam:ListGroups\" , \"iam:ListGroupsForUser\" , \"iam:ListRoles\" , \"iam:ListUserPolicies\" , \"iam:ListUsers\" , \"iam:ListVirtualMFADevices\" , \"s3:ListBucket\" , \"s3:ListAllMyBuckets\" , \"route53:ListHostedZones\" , \"route53:ListResourceRecordSets\" , \"sqs:GetQueueAttributes\" , \"sqs:ListQueues\" , \"rds:DescribeDBInstances\" ], \"Effect\" : \"Allow\" , \"Resource\" : \"*\" }] }","title":"Example IAM Role Policy"},{"location":"configuration/","text":"Configuration \u00b6 Edda Configuration is done via an edda.properties file located at the server root. The file name and location can be overridden with the system property -Dedda.properties=file-path . The linked file shows the default values provided with the server. In the documentation below, $account refers to any value found in the edda.accounts property. If edda.accounts is unset then the configuration options without $account are relevant and configuration options like edda.$accounts.setting will be read as edda.setting . $collectionName refers to any of the collections that Edda crawls. General Options \u00b6 edda.accounts \u00b6 Edda can be configured to poll collections for any number of (comma separated) accounts. Per account configuration options are available below. The default is unset. edda.region \u00b6 This sets the region for the collections that Edda will be polling. For AWS this setting will determine which AWS Endpoint Edda communicates with. The default is unset. edda.$account.region \u00b6 See edda.region . If multiple accounts are being used then you can set the region per account. This could be useful it you intend to poll multiple regions from a single Edda instance. For example, if edda.accounts=prod.us-east-1,prod.eu-west-1 , then you would want to set the region specifically for each account as: edda . prod . us - east - 1 . region = us - east - 1 edda . prod . eu - west - 1 . region = eu - west - 1 AWS Options \u00b6 edda.aws.accessKey \u00b6 The access key for AWS account. If unset Edda will attempt to access the AWS Account using the Default AWS Credential Provider Chain . edda.$account.aws.accessKey \u00b6 See edda.aws.accessKey . Allow for per-account AWS credential settings. edda.aws.secretKey \u00b6 The secret key for AWS account. If accessKey is set, then secretKey must also be set. edda.$account.aws.secretKey \u00b6 See edda.aws.secretKey . Allow for per-account AWS credential settings. Collection Options \u00b6 edda.collection.cache.refresh \u00b6 The time period in milliseconds for how frequent secondary edda servers should reload their in-memory cache of \"live\" resources. Not used if Edda running in stand-alone mode. Default value is 30000 (30 seconds). edda.collection.$account.cache.refresh \u00b6 See edda.collection.cache.refresh . If you want to change the cache refresh rate for a specific account you can set this. edda.collection.$account.$collectionName.cache.refresh \u00b6 See edda.collection.cache.refresh . If you want to change the cache refresh rate for a specific account and specific collection you can set this. You might want to increase the default value if a collection is especially large, or decrease the value, if the collection is small. edda.collection.refresh \u00b6 The time period in milliseconds for how frequent the primary Edda servers should crawl the AWS APIs looking for changed resources. Default value is 60000 (1 minute). edda.collection.$account.refresh \u00b6 See edda.collection.refresh . If you want change the crawl frequency for a specific account, you can change this value. edda.collection.$account.$collectionName.refresh \u00b6 See edda.collection.refresh . If you want change the crawl frequency for a specific account and specific collection, you can change this value. edda.collection.jitter.enabled \u00b6 This boolean value is used to ease the load on your data store upon startup. The default value is false . The jitter cases the initial load of the collection to be staggered randomly over a time period of 2X the value of edda.collection.cache.refresh . You might want to set this to true for development or if you collections are small enough that the data store has no problem loading them all simultaneously. edda.collection.$account.enabled \u00b6 You can disable all collections for a specific account by setting this value to false . The default value is true . edda.collection.$account.$collectionName.enabled \u00b6 You can disable a specific collection for an account by setting this value to false . The default value is true . Crawler Options \u00b6 edda.bean.argPattern \u00b6 Edda polls some API's via java client libraries which return Java Beans. We serialize the Beans to a JSON blob before persisting the data to the data store. This setting is a regular express that determines which properties of the bean to serialize. The default value is [^a-zA-Z0-9_] . Any Bean properties not matching this regular expression will be ignored. edda.crawler.aws.suppressTags \u00b6 AWS provides the ability to add custom tags to many resources that Edda will poll. Sometimes those tags are frequently changing (like tags with timestamp values) which will cause Edda to persist a ton of data that is of little use. If there are tags that you need Edda to ignore you can set this property to a comma separated list of tag names where the value will be automatically replaced with [EDDA_SUPPRESSED] . The default value is unset. edda.crawler.abortWithoutTags \u00b6 AWS APIs for resources that support tagging have an odd quirk: if Amazon is experiencing load problems with their API servers, then they will silently drop all tag information from the responses. Until this problem can be fixed by AWS we have this special setting to allow us to handle this degraded response. If you routinely use tags on your AWS resources you should set this value to true , which will cause crawl results that are missing any tags to be ignored. The default value is false . edda.crawler.$account.abortWithoutTags \u00b6 See edda.crawler.abortWithoutTags . Apply setting to a specific account. edda.crawler.$account.$collectionName.abortWithoutTags \u00b6 See edda.crawler.abortWithoutTags . Apply setting to a specific account and specific collection. edda.crawler.$account.enabled \u00b6 Boolean value to enable or disable crawlers for an account. The default value is true . edda.crawler.$account.$collectionName.enabled \u00b6 Boolean value to enable or disable a crawler for a specific account and specific collection. The default value is true . Elector Options \u00b6 Elector options control how leader election is done in Edda. edda.elector.refresh \u00b6 The time period in milliseconds for how frequently an election should be run to determine a new leader. The default value is 10000 (10 seconds). edda.elector.mongo.collectionName \u00b6 The Mongo Elector uses MongoDB's atomic write capabilities to determine leadership. For this to work every Edda instance in a cluster will attempt to write to a single record in a specific collection. This values lets you customize the collection name. The default value is sys.monitor . edda.elector.mongo.leaderTimeout \u00b6 If Mongo Elector is being used, leaders that have not updated MongoDB within a timeout period will automatically loose leadership and a new leader will be chosen. The default value is 30000 (30 seconds). We recommend the value be 3X the value of edda.elector.refresh . edda.elector.mongo.uniqueEnvName \u00b6 The Mongo Elector will use a unique id to identify each candidate in the election and it gets this unique id from an environment variable. The default value is to use the AWS Instance ID for a unique name, and that value is assumed to be in the EC2_INSTANCE_ID environment variable. If the unique name is in a different environment variable then change this setting. Mongo Options \u00b6 Options for how to connect to MongoDB. You can customize the connections per account or even per collection to be able to spread out the load on MongoDB between more instances. edda.mongo.address \u00b6 The network address:port for where the MongoDB server is running. The default is localhost:27017 . If you are running a MongoDB replication set, then set this value to a comma separated list of all the addresses of the replication set. edda.mongo.$account.address \u00b6 See edda.mongo.address . Set the address for a specific account. edda.mongo.$account.$collectionName.address \u00b6 See edda.mongo.address . Set the address for a specific account and collection. edda.mongo.database \u00b6 Specify the name of the database in the MondoDB server to use. The default value is edda . edda.mongo.$account.database \u00b6 See edda.mongo.database . Set the database name to use for a specific account. edda.mongo.$account.$collectionName.database \u00b6 See edda.mongo.database . Set the database name to use for a specific account and collection. edda.mongo.user \u00b6 Specify the user name to use when connecting to the MongoDB server. The default is unset. edda.mongo.$account.user \u00b6 See edda.mongo.user . Set the user for a specific account. edda.mongo.$account.$collectionName.user \u00b6 See edda.mongo.user . Set the user for a specific account edda.mongo.password \u00b6 Specify the password to use when connecting to the MongoDB server. The default is unset. edda.mongo.$account.password \u00b6 See edda.mongo.password . Set the password for a specific account. edda.mongo.$account.$collectioName.password \u00b6 See edda.mongo.password . Set the password for a specific account and collection.","title":"Configuration"},{"location":"configuration/#configuration","text":"Edda Configuration is done via an edda.properties file located at the server root. The file name and location can be overridden with the system property -Dedda.properties=file-path . The linked file shows the default values provided with the server. In the documentation below, $account refers to any value found in the edda.accounts property. If edda.accounts is unset then the configuration options without $account are relevant and configuration options like edda.$accounts.setting will be read as edda.setting . $collectionName refers to any of the collections that Edda crawls.","title":"Configuration"},{"location":"configuration/#general-options","text":"","title":"General Options"},{"location":"configuration/#eddaaccounts","text":"Edda can be configured to poll collections for any number of (comma separated) accounts. Per account configuration options are available below. The default is unset.","title":"edda.accounts"},{"location":"configuration/#eddaregion","text":"This sets the region for the collections that Edda will be polling. For AWS this setting will determine which AWS Endpoint Edda communicates with. The default is unset.","title":"edda.region"},{"location":"configuration/#eddaaccountregion","text":"See edda.region . If multiple accounts are being used then you can set the region per account. This could be useful it you intend to poll multiple regions from a single Edda instance. For example, if edda.accounts=prod.us-east-1,prod.eu-west-1 , then you would want to set the region specifically for each account as: edda . prod . us - east - 1 . region = us - east - 1 edda . prod . eu - west - 1 . region = eu - west - 1","title":"edda.$account.region"},{"location":"configuration/#aws-options","text":"","title":"AWS Options"},{"location":"configuration/#eddaawsaccesskey","text":"The access key for AWS account. If unset Edda will attempt to access the AWS Account using the Default AWS Credential Provider Chain .","title":"edda.aws.accessKey"},{"location":"configuration/#eddaaccountawsaccesskey","text":"See edda.aws.accessKey . Allow for per-account AWS credential settings.","title":"edda.$account.aws.accessKey"},{"location":"configuration/#eddaawssecretkey","text":"The secret key for AWS account. If accessKey is set, then secretKey must also be set.","title":"edda.aws.secretKey"},{"location":"configuration/#eddaaccountawssecretkey","text":"See edda.aws.secretKey . Allow for per-account AWS credential settings.","title":"edda.$account.aws.secretKey"},{"location":"configuration/#collection-options","text":"","title":"Collection Options"},{"location":"configuration/#eddacollectioncacherefresh","text":"The time period in milliseconds for how frequent secondary edda servers should reload their in-memory cache of \"live\" resources. Not used if Edda running in stand-alone mode. Default value is 30000 (30 seconds).","title":"edda.collection.cache.refresh"},{"location":"configuration/#eddacollectionaccountcacherefresh","text":"See edda.collection.cache.refresh . If you want to change the cache refresh rate for a specific account you can set this.","title":"edda.collection.$account.cache.refresh"},{"location":"configuration/#eddacollectionaccountcollectionnamecacherefresh","text":"See edda.collection.cache.refresh . If you want to change the cache refresh rate for a specific account and specific collection you can set this. You might want to increase the default value if a collection is especially large, or decrease the value, if the collection is small.","title":"edda.collection.$account.$collectionName.cache.refresh"},{"location":"configuration/#eddacollectionrefresh","text":"The time period in milliseconds for how frequent the primary Edda servers should crawl the AWS APIs looking for changed resources. Default value is 60000 (1 minute).","title":"edda.collection.refresh"},{"location":"configuration/#eddacollectionaccountrefresh","text":"See edda.collection.refresh . If you want change the crawl frequency for a specific account, you can change this value.","title":"edda.collection.$account.refresh"},{"location":"configuration/#eddacollectionaccountcollectionnamerefresh","text":"See edda.collection.refresh . If you want change the crawl frequency for a specific account and specific collection, you can change this value.","title":"edda.collection.$account.$collectionName.refresh"},{"location":"configuration/#eddacollectionjitterenabled","text":"This boolean value is used to ease the load on your data store upon startup. The default value is false . The jitter cases the initial load of the collection to be staggered randomly over a time period of 2X the value of edda.collection.cache.refresh . You might want to set this to true for development or if you collections are small enough that the data store has no problem loading them all simultaneously.","title":"edda.collection.jitter.enabled"},{"location":"configuration/#eddacollectionaccountenabled","text":"You can disable all collections for a specific account by setting this value to false . The default value is true .","title":"edda.collection.$account.enabled"},{"location":"configuration/#eddacollectionaccountcollectionnameenabled","text":"You can disable a specific collection for an account by setting this value to false . The default value is true .","title":"edda.collection.$account.$collectionName.enabled"},{"location":"configuration/#crawler-options","text":"","title":"Crawler Options"},{"location":"configuration/#eddabeanargpattern","text":"Edda polls some API's via java client libraries which return Java Beans. We serialize the Beans to a JSON blob before persisting the data to the data store. This setting is a regular express that determines which properties of the bean to serialize. The default value is [^a-zA-Z0-9_] . Any Bean properties not matching this regular expression will be ignored.","title":"edda.bean.argPattern"},{"location":"configuration/#eddacrawlerawssuppresstags","text":"AWS provides the ability to add custom tags to many resources that Edda will poll. Sometimes those tags are frequently changing (like tags with timestamp values) which will cause Edda to persist a ton of data that is of little use. If there are tags that you need Edda to ignore you can set this property to a comma separated list of tag names where the value will be automatically replaced with [EDDA_SUPPRESSED] . The default value is unset.","title":"edda.crawler.aws.suppressTags"},{"location":"configuration/#eddacrawlerabortwithouttags","text":"AWS APIs for resources that support tagging have an odd quirk: if Amazon is experiencing load problems with their API servers, then they will silently drop all tag information from the responses. Until this problem can be fixed by AWS we have this special setting to allow us to handle this degraded response. If you routinely use tags on your AWS resources you should set this value to true , which will cause crawl results that are missing any tags to be ignored. The default value is false .","title":"edda.crawler.abortWithoutTags"},{"location":"configuration/#eddacrawleraccountabortwithouttags","text":"See edda.crawler.abortWithoutTags . Apply setting to a specific account.","title":"edda.crawler.$account.abortWithoutTags"},{"location":"configuration/#eddacrawleraccountcollectionnameabortwithouttags","text":"See edda.crawler.abortWithoutTags . Apply setting to a specific account and specific collection.","title":"edda.crawler.$account.$collectionName.abortWithoutTags"},{"location":"configuration/#eddacrawleraccountenabled","text":"Boolean value to enable or disable crawlers for an account. The default value is true .","title":"edda.crawler.$account.enabled"},{"location":"configuration/#eddacrawleraccountcollectionnameenabled","text":"Boolean value to enable or disable a crawler for a specific account and specific collection. The default value is true .","title":"edda.crawler.$account.$collectionName.enabled"},{"location":"configuration/#elector-options","text":"Elector options control how leader election is done in Edda.","title":"Elector Options"},{"location":"configuration/#eddaelectorrefresh","text":"The time period in milliseconds for how frequently an election should be run to determine a new leader. The default value is 10000 (10 seconds).","title":"edda.elector.refresh"},{"location":"configuration/#eddaelectormongocollectionname","text":"The Mongo Elector uses MongoDB's atomic write capabilities to determine leadership. For this to work every Edda instance in a cluster will attempt to write to a single record in a specific collection. This values lets you customize the collection name. The default value is sys.monitor .","title":"edda.elector.mongo.collectionName"},{"location":"configuration/#eddaelectormongoleadertimeout","text":"If Mongo Elector is being used, leaders that have not updated MongoDB within a timeout period will automatically loose leadership and a new leader will be chosen. The default value is 30000 (30 seconds). We recommend the value be 3X the value of edda.elector.refresh .","title":"edda.elector.mongo.leaderTimeout"},{"location":"configuration/#eddaelectormongouniqueenvname","text":"The Mongo Elector will use a unique id to identify each candidate in the election and it gets this unique id from an environment variable. The default value is to use the AWS Instance ID for a unique name, and that value is assumed to be in the EC2_INSTANCE_ID environment variable. If the unique name is in a different environment variable then change this setting.","title":"edda.elector.mongo.uniqueEnvName"},{"location":"configuration/#mongo-options","text":"Options for how to connect to MongoDB. You can customize the connections per account or even per collection to be able to spread out the load on MongoDB between more instances.","title":"Mongo Options"},{"location":"configuration/#eddamongoaddress","text":"The network address:port for where the MongoDB server is running. The default is localhost:27017 . If you are running a MongoDB replication set, then set this value to a comma separated list of all the addresses of the replication set.","title":"edda.mongo.address"},{"location":"configuration/#eddamongoaccountaddress","text":"See edda.mongo.address . Set the address for a specific account.","title":"edda.mongo.$account.address"},{"location":"configuration/#eddamongoaccountcollectionnameaddress","text":"See edda.mongo.address . Set the address for a specific account and collection.","title":"edda.mongo.$account.$collectionName.address"},{"location":"configuration/#eddamongodatabase","text":"Specify the name of the database in the MondoDB server to use. The default value is edda .","title":"edda.mongo.database"},{"location":"configuration/#eddamongoaccountdatabase","text":"See edda.mongo.database . Set the database name to use for a specific account.","title":"edda.mongo.$account.database"},{"location":"configuration/#eddamongoaccountcollectionnamedatabase","text":"See edda.mongo.database . Set the database name to use for a specific account and collection.","title":"edda.mongo.$account.$collectionName.database"},{"location":"configuration/#eddamongouser","text":"Specify the user name to use when connecting to the MongoDB server. The default is unset.","title":"edda.mongo.user"},{"location":"configuration/#eddamongoaccountuser","text":"See edda.mongo.user . Set the user for a specific account.","title":"edda.mongo.$account.user"},{"location":"configuration/#eddamongoaccountcollectionnameuser","text":"See edda.mongo.user . Set the user for a specific account","title":"edda.mongo.$account.$collectionName.user"},{"location":"configuration/#eddamongopassword","text":"Specify the password to use when connecting to the MongoDB server. The default is unset.","title":"edda.mongo.password"},{"location":"configuration/#eddamongoaccountpassword","text":"See edda.mongo.password . Set the password for a specific account.","title":"edda.mongo.$account.password"},{"location":"configuration/#eddamongoaccountcollectionamepassword","text":"See edda.mongo.password . Set the password for a specific account and collection.","title":"edda.mongo.$account.$collectioName.password"},{"location":"docker-start-guide/","text":"Introduction \u00b6 The Zero to Docker project tracks the Dockerfiles used to create official Netflix OSS containers on Docker Hub . The Edda container provides an edda.properties template that drops the default MongoDB configuration in favor of using DynamoDB for leader election and S3 for persistent storage of the crawl results. The launch technique for this container allows for the injection of AWS keys through the template file for non-production testing purposes, although using on-instance keys from an IAM role is more secure. # build command docker build - t netflixoss / edda $D OCKERFILE_HOME # interactive run command docker run \\ -- name edda \\ - p 8080 : 8080 \\ - v ` pwd ` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 # detached run command docker run - d \\ -- name edda \\ - p 8080 : 8080 \\ - v ` pwd ` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 # view port mappings docker port edda # connect interactive bash shell to a container docker exec - it edda bash # explore running containers docker ps - a docker start $C ONTAINER_NAME_OR_ID docker stop $C ONTAINER_NAME_OR_ID docker rm $C ONTAINER_NAME_OR_ID # explore container images docker images docker pull $ IMAGE_NAME_OR_ID docker rmi $ IMAGE_NAME_OR_ID docker rmi - f $ IMAGE_NAME_OR_ID The minimal edda.properties template is listed below. The accessKey, secretKey and bucket configuration options should be replaced with appropriate values prior to copying the file into the container. # -- change these properties --------------------------------------------- edda . region = us - east - 1 edda . aws . accessKey = yourAccessKey edda . aws . secretKey = yourSecretKey edda . s3current . bucket = yourBucket # ------------------------------------------------------------------------ edda . collection . aws . stacks . refresh = 3600000 edda . collection . cache . refresh = 30000 edda . collection . jitter . enabled = false edda . collection . refresh = 120000 edda . bean . argPattern = [ ^ a - zA - Z0 - 9 _ ] edda . datastore . class = edda . elector . class = com . netflix . edda . aws . DynamoDBElector edda . elector . dynamodb . account = edda . elector . dynamodb . leaderTimeout = 60000 edda . elector . dynamodb . tableName = edda - leader edda . elector . dynamodb . readCapacity = 5 edda . elector . dynamodb . writeCapacity = 1 edda . datastore . current . class = com . netflix . edda . aws . S3CurrentDatastore edda . s3current . account = edda . s3current . table = edda - s3current - collection - index - dev edda . s3current . readCapacity = 10 edda . s3current . writeCapacity = 1 edda . s3current . locationPrefix = edda / s3current / dev See Configuration and edda.properties for details on additional configuration options that can be set. The Tomcat instance in the Edda container will run on port 8080 and this will be mapped to port 0.0.0.0:8080 on the host machine running the container. Using this mapping, you can test Edda with a curl command to one of the endpoints. If you use curl for testing, you will want to disable range queries by setting the globoff option. See REST API for more details on endpoints. curl -g 'localhost:8080/api/v2/view/instances;_pp' Testing with Vagrant \u00b6 The Vagrant project leverages Virtual Box and published guest boxes to automate the provisioning of virtual machines on your local workstation. You can use the following Vagrantfile to stand up an environment for testing the Docker container. # -*- mode: ruby -*- # vi: set ft=ruby : $script = << SCRIPT add-apt-repository ppa:webupd8team/java apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 echo deb https://get.docker.com/ubuntu docker main > /etc/apt/sources.list.d/docker.list apt-get update JAVA_VER=8 echo oracle-java${JAVA_VER}-installer shared/accepted-oracle-license-v1-1 select true | sudo /usr/bin/debconf-set-selections apt-get install -y --force-yes --no-install-recommends oracle-java${JAVA_VER}-installer oracle-java${JAVA_VER}-set-default 2>/dev/null apt-get install -y git lxc-docker mkdir git pushd git git clone https://github.com/Netflix/edda.git git clone https://github.com/Netflix-Skunkworks/zerotodocker.git popd chown -R vagrant:vagrant git SCRIPT Vagrant . configure ( 2 ) do | config | config . vm . box = \"ubuntu/trusty64\" config . vm . provider \"virtualbox\" do | vb | vb . name = \"nflxoss_trusty64\" vb . memory = 4096 vb . cpus = 2 end config . vm . provision \"shell\" , inline : $script end To use this Vagrantfile : vagrant up vagrant ssh sudo docker ... Testing with Boot2Docker \u00b6 The Boot2Docker project leverages Virtual Box and Tiny Core Linux to provide a thin execution environment for Docker containers. To allow access to the Edda container in the VM from your terminal, you need to configure a port forwarding rule on the Virtual Box guest. boot2docker init VBoxManage modifyvm \"boot2docker-vm\" -- natpf1 \"tcp-port8080,tcp,,8080,,8080\" boot2docker up $ ( boot2docker shellinit ) docker run \\ -- name edda \\ - p 8080 : 8080 \\ - v `pwd` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 curl - g 'localhost:8080/api/v2/view/instances;_pp'","title":"Docker Start Guide"},{"location":"docker-start-guide/#introduction","text":"The Zero to Docker project tracks the Dockerfiles used to create official Netflix OSS containers on Docker Hub . The Edda container provides an edda.properties template that drops the default MongoDB configuration in favor of using DynamoDB for leader election and S3 for persistent storage of the crawl results. The launch technique for this container allows for the injection of AWS keys through the template file for non-production testing purposes, although using on-instance keys from an IAM role is more secure. # build command docker build - t netflixoss / edda $D OCKERFILE_HOME # interactive run command docker run \\ -- name edda \\ - p 8080 : 8080 \\ - v ` pwd ` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 # detached run command docker run - d \\ -- name edda \\ - p 8080 : 8080 \\ - v ` pwd ` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 # view port mappings docker port edda # connect interactive bash shell to a container docker exec - it edda bash # explore running containers docker ps - a docker start $C ONTAINER_NAME_OR_ID docker stop $C ONTAINER_NAME_OR_ID docker rm $C ONTAINER_NAME_OR_ID # explore container images docker images docker pull $ IMAGE_NAME_OR_ID docker rmi $ IMAGE_NAME_OR_ID docker rmi - f $ IMAGE_NAME_OR_ID The minimal edda.properties template is listed below. The accessKey, secretKey and bucket configuration options should be replaced with appropriate values prior to copying the file into the container. # -- change these properties --------------------------------------------- edda . region = us - east - 1 edda . aws . accessKey = yourAccessKey edda . aws . secretKey = yourSecretKey edda . s3current . bucket = yourBucket # ------------------------------------------------------------------------ edda . collection . aws . stacks . refresh = 3600000 edda . collection . cache . refresh = 30000 edda . collection . jitter . enabled = false edda . collection . refresh = 120000 edda . bean . argPattern = [ ^ a - zA - Z0 - 9 _ ] edda . datastore . class = edda . elector . class = com . netflix . edda . aws . DynamoDBElector edda . elector . dynamodb . account = edda . elector . dynamodb . leaderTimeout = 60000 edda . elector . dynamodb . tableName = edda - leader edda . elector . dynamodb . readCapacity = 5 edda . elector . dynamodb . writeCapacity = 1 edda . datastore . current . class = com . netflix . edda . aws . S3CurrentDatastore edda . s3current . account = edda . s3current . table = edda - s3current - collection - index - dev edda . s3current . readCapacity = 10 edda . s3current . writeCapacity = 1 edda . s3current . locationPrefix = edda / s3current / dev See Configuration and edda.properties for details on additional configuration options that can be set. The Tomcat instance in the Edda container will run on port 8080 and this will be mapped to port 0.0.0.0:8080 on the host machine running the container. Using this mapping, you can test Edda with a curl command to one of the endpoints. If you use curl for testing, you will want to disable range queries by setting the globoff option. See REST API for more details on endpoints. curl -g 'localhost:8080/api/v2/view/instances;_pp'","title":"Introduction"},{"location":"docker-start-guide/#testing-with-vagrant","text":"The Vagrant project leverages Virtual Box and published guest boxes to automate the provisioning of virtual machines on your local workstation. You can use the following Vagrantfile to stand up an environment for testing the Docker container. # -*- mode: ruby -*- # vi: set ft=ruby : $script = << SCRIPT add-apt-repository ppa:webupd8team/java apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9 echo deb https://get.docker.com/ubuntu docker main > /etc/apt/sources.list.d/docker.list apt-get update JAVA_VER=8 echo oracle-java${JAVA_VER}-installer shared/accepted-oracle-license-v1-1 select true | sudo /usr/bin/debconf-set-selections apt-get install -y --force-yes --no-install-recommends oracle-java${JAVA_VER}-installer oracle-java${JAVA_VER}-set-default 2>/dev/null apt-get install -y git lxc-docker mkdir git pushd git git clone https://github.com/Netflix/edda.git git clone https://github.com/Netflix-Skunkworks/zerotodocker.git popd chown -R vagrant:vagrant git SCRIPT Vagrant . configure ( 2 ) do | config | config . vm . box = \"ubuntu/trusty64\" config . vm . provider \"virtualbox\" do | vb | vb . name = \"nflxoss_trusty64\" vb . memory = 4096 vb . cpus = 2 end config . vm . provision \"shell\" , inline : $script end To use this Vagrantfile : vagrant up vagrant ssh sudo docker ...","title":"Testing with Vagrant"},{"location":"docker-start-guide/#testing-with-boot2docker","text":"The Boot2Docker project leverages Virtual Box and Tiny Core Linux to provide a thin execution environment for Docker containers. To allow access to the Edda container in the VM from your terminal, you need to configure a port forwarding rule on the Virtual Box guest. boot2docker init VBoxManage modifyvm \"boot2docker-vm\" -- natpf1 \"tcp-port8080,tcp,,8080,,8080\" boot2docker up $ ( boot2docker shellinit ) docker run \\ -- name edda \\ - p 8080 : 8080 \\ - v `pwd` / edda . properties : / tomcat / webapps / ROOT / WEB - INF / classes / edda . properties \\ netflixoss / edda : 2 . 1 curl - g 'localhost:8080/api/v2/view/instances;_pp'","title":"Testing with Boot2Docker"},{"location":"quick-start-guide/","text":"Git Fork & Clone \u00b6 If you have a fork of the Edda repo and you see the following error when trying to start sbt: java . lang . RuntimeException : Setting value cannot be null : { file :... / edda / } /*:version Then you need to add the upstream repository and fetch it, so that you have tag data available: git remote add upstream https://github.com/Netflix/edda.git git fetch upstream AWS Credentials \u00b6 Proper read-only credentials are required to allow Edda to crawl AWS resources in your account. The fastest way to get started is to create a new set of PowerUser credentials in the Identity and Access Management console. The downside to this approach is that you need to be careful about leaking these credentials, since they are long-lived and have the ability to modify items in your account. Do not use this approach to run Edda in your AWS account; rather, you should use instance credentials, which are rotated regularly. The best way to obtain keys for local testing is to create an EddaInstanceProfile IAM role, create an Edda role and launch an instance with the instance profile. This will provide credentials which only have permission to read data from AWS APIs and are only valid for a few hours, which helps reduce the risk of leaking them. See AWS Permissions for more details on configuring these IAM roles. When you are ready to run Edda in your AWS account, this is the approach you should use for providing credentials. Run Edda Locally \u00b6 Using established AWS credentials: export AWS_ACCESS_KEY_ID = yourAccessKey export AWS_SECRET_KEY = yourSecretKey Using time-limited AWS instance credentials: # gather credentials from an AWS instance curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/EddaInstanceProfile # using the result of the previous step on your machine CREDENTIALS = \"...\" export AWS_ACCESS_KEY_ID = $( echo \"CREDENTIALS\" | jq -r '.AccessKeyId' ) export AWS_SECRET_ACCESS_KEY = $( echo \"CREDENTIALS\" | jq -r '.SecretAccessKey' ) export AWS_SESSION_TOKEN = $( echo \"CREDENTIALS\" | jq -r '.Token' ) The default values in edda.properties will use a stack name of dev and run against the us-east-1 region: sbt > jetty:start You should see Edda start and begin processing all the resources under your AWS account for the region you specified. The output will be pretty verbose, it will log for each new record it sees, each record that is no longer active, and it will log unified diff output for all changes that are detected. The first time Edda is run it can take several minutes to insert all of the AWS resources into S3, depending on how many resources you have. The Jetty server will be listening at http://localhost:8080 . API Testing \u00b6 You can start playing with the REST APIs on your running Edda server. The jq CLI tool is recommended for working JSON API data. Set the base URL for your local Edda instance: export EDDA = http://localhost:8080 Find out how many instances you have: curl $EDDA /api/v2/view/instances | jq 'length' Make the output easier to read with either jq or the pretty-printer. The jq tool is fast and allows you to filter the JSON response; the pretty-printer will translate timestamps into readable strings. Quotes are necessary on the shell, due to the use of the ; character as a URL separator. curl $EDDA /api/v2/view/instances | jq . curl \" $EDDA /api/v2/view/instances;_pp\" Find an instance with a known publicIpAddress : curl \" $EDDA /api/v2/view/instances;publicIpAddress=1.2.3.4\" See the details of that instance: curl $EDDA /view/instances/i-012345678a | jq . Use Field Selectors to pull out the instance state and privateIpAddress : curl \" $EDDA /view/instances/i-012345678a;_pp:(state:(name),privateIpAddress)\" Build Edda Artifact \u00b6 Build Edda, run tests and produce a war file: make build make war You can find the war file in the following location: target/scala-2.11/edda_2.11-3.0.0-SNAPSHOT.war This artifact is suitable for deployment with Tomcat or similar servlet containers in your AWS account. Configure Edda \u00b6 The defaults should work for most simple cases. See the Configuration page for details on the various configuration options. Further Reading \u00b6 Continue experimenting with the REST API and matrix arguments. Configuration options are available to customize the Edda service.","title":"Quick Start Guide"},{"location":"quick-start-guide/#git-fork-clone","text":"If you have a fork of the Edda repo and you see the following error when trying to start sbt: java . lang . RuntimeException : Setting value cannot be null : { file :... / edda / } /*:version Then you need to add the upstream repository and fetch it, so that you have tag data available: git remote add upstream https://github.com/Netflix/edda.git git fetch upstream","title":"Git Fork &amp; Clone"},{"location":"quick-start-guide/#aws-credentials","text":"Proper read-only credentials are required to allow Edda to crawl AWS resources in your account. The fastest way to get started is to create a new set of PowerUser credentials in the Identity and Access Management console. The downside to this approach is that you need to be careful about leaking these credentials, since they are long-lived and have the ability to modify items in your account. Do not use this approach to run Edda in your AWS account; rather, you should use instance credentials, which are rotated regularly. The best way to obtain keys for local testing is to create an EddaInstanceProfile IAM role, create an Edda role and launch an instance with the instance profile. This will provide credentials which only have permission to read data from AWS APIs and are only valid for a few hours, which helps reduce the risk of leaking them. See AWS Permissions for more details on configuring these IAM roles. When you are ready to run Edda in your AWS account, this is the approach you should use for providing credentials.","title":"AWS Credentials"},{"location":"quick-start-guide/#run-edda-locally","text":"Using established AWS credentials: export AWS_ACCESS_KEY_ID = yourAccessKey export AWS_SECRET_KEY = yourSecretKey Using time-limited AWS instance credentials: # gather credentials from an AWS instance curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/EddaInstanceProfile # using the result of the previous step on your machine CREDENTIALS = \"...\" export AWS_ACCESS_KEY_ID = $( echo \"CREDENTIALS\" | jq -r '.AccessKeyId' ) export AWS_SECRET_ACCESS_KEY = $( echo \"CREDENTIALS\" | jq -r '.SecretAccessKey' ) export AWS_SESSION_TOKEN = $( echo \"CREDENTIALS\" | jq -r '.Token' ) The default values in edda.properties will use a stack name of dev and run against the us-east-1 region: sbt > jetty:start You should see Edda start and begin processing all the resources under your AWS account for the region you specified. The output will be pretty verbose, it will log for each new record it sees, each record that is no longer active, and it will log unified diff output for all changes that are detected. The first time Edda is run it can take several minutes to insert all of the AWS resources into S3, depending on how many resources you have. The Jetty server will be listening at http://localhost:8080 .","title":"Run Edda Locally"},{"location":"quick-start-guide/#api-testing","text":"You can start playing with the REST APIs on your running Edda server. The jq CLI tool is recommended for working JSON API data. Set the base URL for your local Edda instance: export EDDA = http://localhost:8080 Find out how many instances you have: curl $EDDA /api/v2/view/instances | jq 'length' Make the output easier to read with either jq or the pretty-printer. The jq tool is fast and allows you to filter the JSON response; the pretty-printer will translate timestamps into readable strings. Quotes are necessary on the shell, due to the use of the ; character as a URL separator. curl $EDDA /api/v2/view/instances | jq . curl \" $EDDA /api/v2/view/instances;_pp\" Find an instance with a known publicIpAddress : curl \" $EDDA /api/v2/view/instances;publicIpAddress=1.2.3.4\" See the details of that instance: curl $EDDA /view/instances/i-012345678a | jq . Use Field Selectors to pull out the instance state and privateIpAddress : curl \" $EDDA /view/instances/i-012345678a;_pp:(state:(name),privateIpAddress)\"","title":"API Testing"},{"location":"quick-start-guide/#build-edda-artifact","text":"Build Edda, run tests and produce a war file: make build make war You can find the war file in the following location: target/scala-2.11/edda_2.11-3.0.0-SNAPSHOT.war This artifact is suitable for deployment with Tomcat or similar servlet containers in your AWS account.","title":"Build Edda Artifact"},{"location":"quick-start-guide/#configure-edda","text":"The defaults should work for most simple cases. See the Configuration page for details on the various configuration options.","title":"Configure Edda"},{"location":"quick-start-guide/#further-reading","text":"Continue experimenting with the REST API and matrix arguments. Configuration options are available to customize the Edda service.","title":"Further Reading"},{"location":"resiliency/","text":"The Quick Start Guide shows how to quickly get started running Edda, however you will probably note it is far from a resilient deployment. This document describes how Edda is run in the production environment at Netflix. The Edda deployment is comprised of two logical clusters: one for the Edda frontend and one for the MongoDB database. Two different AMI's have been created: one for the Edda frontend and one for the MongoDB install. For the Edda frontend, the typical setup is four instances under one auto-scaling group (ASG). The ASG is configured to run out of two availability zones (AZ), so there will be two instances running in each AZ. Then there is an Elastic Load Balancer (ELB) that routes traffic to each of the instances. This configuration allows for Edda to continue operating even during a complete AZ outage. Two instances per AZ are run because the ELB's can have issues when all instances within a single AZ go down, so it is desirable to have at least one instance in an AZ after things like ChaosMonkey attacks. In some smaller regions where the risk of Edda becoming unavailable during an AZ outage is more acceptable then the setup can be just two instances in one AZ to save on the costs. In larger regions, the Edda frontend clusters can be scaled up to six or eight instances to handle higher HTTP request load. Edda is designed to have one 'leader' per cluster. The leader will do all the AWS crawling, and update the datastore, and the others will simply handle the http request traffic. Edda will automatically pick a leader among the cluster and it currently uses MongoDB to negotiate leadership. Once the cluster is set up, it should take care of itself for the most part, leaders will automatically be reassigned if they become non-responsive. If an instance starts to have problems it is easiest to just terminate it and let the ASG recreate it. For MongoDB it is a bit more complicated. It is run with a replica set of three instances. Basically MongoDB operates fine when one of the instances goes down, but when two go down (leaving only the PRIMARY), then it stops accepting writes. The cluster is setup in AWS to minimize risk of multiple instances being down at once. This means that each of the three instances needs to be in a different AZ. For this, create three different ASGs each configured to run one instance in one AZ (all different AZ's). On top of the ASGs, use an Elastic IP (EIP) for each instance running MongoDB, so that when an instance comes up, it will be assigned a known IP. The EIP is important since the MongoDB replset membership is specified by the IP and hostname, so those need to be constant for the deployment. You might be able to use ELBs (one for each ASG) instead of EIPs, which might be a bit easier to manage, but it is untried and we don't know if it will work. Assigning an EIP to an instance is a manual process so if you have to rebuild an instance then you have to ssh into the new instance and reassign the EIP (Netflix has an internal tool that does this, but unfortunately it is not open source). For backing up MongoDB, there is nothing as fancy as Priam. The easiest thing is to take a daily backup via a cron job. The backup is basically, mongodump, tar, and push to S3. Although to use the backups that would require losing all three MongoDB instances, in three different AZs, which is unlikely. So short of user error, (i.e. someone accidentally deleting all the MongoDB ASGs), I would not expect to ever need a backup. Of course at Netflix, Asgard is used, so it makes most of this pretty easy. The hardest part would likely be getting your AMI's set up and Netflix has a tool that should help with that which is being open sourced soon.","title":"Resiliency"},{"location":"rest-api/","text":"REST API \u00b6 Introduction \u00b6 Resources can be fetched using HTTP GET requests. The output will always be JSON (or JSONP if _callback is used). In many cases the results of the GET's will be identical to an equivalent API call to the AWS service, however Edda will preserve cached copies of the API calls so users can query what the resource looked like at a specific time, or can quickly scan through all changes to a resource. Using Matrix Arguments you can find specific resources and with Field Selectors you can extract just the data elements you are interested. General \u00b6 All APIs might return an error. There will be a non 200 HTTP status code returned with content formatted as: { \"code\" : 404 , \"message\" : \"not found\" } Select Matrix Arguments \u00b6 You can use matrix arguments to query for specific resources. The argument name should map to the location in the document with a . character separating hierarchy levels. Given the following AWS AutoScalingGroup document structure: { \"launchConfigurationName\" : \"edda-201106231306\" , \"instances\" : [ { \"launchConfigurationName\" : \"edda-201106231306\" , \"instanceId\" : \"i-0123456789\" , \"lifecycleState\" : \"InService\" , \"availabilityZone\" : \"us-east-1d\" , \"healthStatus\" : \"Healthy\" } ], \"availabilityZones\" : [ \"us-east-1c\" , \"us-east-1d\" , \"us-east-1e\" ], \"autoScalingGroupName\" : \"edda\" } You could match it with these any of these queries: # set the base url export ASGS = \"http://localhost:8080/edda/api/v2/aws/autoScalingGroups\" # find an asg with a launch config curl \" $ASGS ;launchConfigurationName=edda-201106231306\" # find all asgs configured for a zone curl \" $ASGS ;availabilityZones=us-east-1e\" # find all asgs with at least one instance in a zone curl \" $ASGS ;instances.availabilityZone=us-east-1e\" Given this AWS Instance document structure: { \"instanceId\" : \"i-0123456789\" , \"publicIpAddress\" : \"1.2.3.4\" , \"tags\" : [ { \"key\" : \"aws:autoscaling:groupName\" , \"value\" : \"edda-v107\" } ], \"state\" : { \"name\" : \"terminated\" , \"code\" : 16 }, \"securityGroups\" : [ { \"groupId\" : \"sg-0123456789\" , \"groupName\" : \"corp\" } ], \"instanceType\" : \"m2.2xlarge\" , \"privateIpAddress\" : \"10.10.10.1\" , \"publicDnsName\" : \"ec2-1-2-3-4.compute-1.amazonaws.com\" , \"privateDnsName\" : \"ip-10-10-10-1.ec2.internal\" , \"imageId\" : \"ami-0123456789\" , \"placement\" : { \"tenancy\" : \"default\" , \"availabilityZone\" : \"us-east-1e\" , \"groupName\" : \"\" } } You could match it with any of these queries: # set the base url export INSTANCES = \"http://localhost:8080/edda/api/v2/view/instances\" # find an instance with a known publicIpAddress curl \" $INSTANCES ;publicIpAddress=1.2.3.4\" # find instances in a given state curl \" $INSTANCES ;state.name=terminated\" # find instances given a security group name curl \" $INSTANCES ;securityGroups.groupName=corp\" # find instances for a zone curl \" $INSTANCES ;placement.availabilityZone=us-east-1e\" Modifier Matrix Arguments \u00b6 All Modifier Matrix Arguments begin with a _ to try to avoid conflicts with the Select Matrix Arguments as described above. _all \u00b6 By default, the APIs only return the most recent documents. If you need to see every document revision then then you can set _all . Typically this Modifier would be used with _diff or _meta . The _all parameter implies _expand . For example, you can use Field Selectors and _all to see all the state changes of a given instance, and use _meta to see when those changes happened: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_all;_pp;_meta:(stime,ltime,data:(state:(name)))' _at \u00b6 The value of this parameter is a timestamp in milliseconds. You can use _at to view a document as it appeared in the past. If a document has changed (asg has new instances, instance has had eip attached) or is no longer valid (instance was terminated) then you can use _at to see the document as it was in the past. If you query for a document that is no longer valid you will get a 410 GONE error when fetched, and you can use _at to find the last seen copy: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_pp;_at=1340837213797' _callback \u00b6 The value of this parameter is the name of the callback. This feature is used to provide a jsonp callback. The response content-type will be set to application/javascript and the content will be wrapped with the provided callback name. curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_pp;_at=1340837213797;_callback=mycallback' _diff \u00b6 The value of this parameter is an integer representing the number of lines of context you wish to see. _diff can be used to get a unified diff when several revisions of a document are found. This is typically used with _all , _since , _until and _limit . You can pass a value with the _diff argument as the number of lines of context. If you want the full document, leave a blank value for _diff . For example, to see the changes of a securityGroup over a given time range: curl \"http://localhost:8080/edda/api/v2/aws/securityGroups/sg-0123456789;_since=1340398800000;_until=1340402400000;_all;_diff=0\" To see the diffs in the last 4 revisions of an instance: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_diff=0;_all;_limit=4' _expand \u00b6 By default, when you get a collection without specifying a resource id, you will receive an index listing that contains only get the resource names. If you want to see the full details of each resource in the list, add the _expand parameter: # index listing curl 'http://localhost:8080/edda/api/v2/view/instances;_limit=2;_pp' # expanded curl 'http://localhost:8080/edda/api/v2/view/instances;_limit=2;_pp;_expand' _limit \u00b6 The value of this parameter is an integer. Any time a list is returned, you can restrict the quantity returned with _limit . It is frequently used with _all to see the last N revisions of a document. See the usage in _diff for an example use case. _live \u00b6 This option should rarely be used. Edda is built on top of a MongoDB datastore, but there is some in memory caching in the application servers. There is a possibility for the caches to be out of sync for brief period of time (cache is refreshed every 60s). If variation in the GET responses cannot be tolerated, then you can use _live to direct the queries directly to the MongoDB datastore. _meta \u00b6 Edda collects some metadata for the documents it stores. If you use the _meta Modifier then the related metadata will be returned along the document. Here are the keys you will see: stime : Timestamp that Edda detected the document modification. ltime : Timestamp for when the document was last valid. mtime : Timestamp of when meta data was modified; it is typically the same as the stime . ctime : Either the create time of the document, or, if the the document has no create or start time available, then it will be the first time Edda saw the document. tags : Map of key-value pairs that are used for internal Edda mappings. id : Primary identifier for the document (instanceId, autoScalingGroupName, etc). data : The document as stored. _id : Internal primary key, formatted as id|stime , which isused by MongoDB to track the revisions. When using _meta with Select Matrix Arguments or Field Selectors, the document root changes and you will need to modify parameter names to match (i.e. add a data. prefix when you want to filter results with _meta and Select Matrix Arguments). # find all instances that have ever had an IP and print the instance ids and the tags : curl 'http://localhost:8080/edda/api/v2/view/instances;publicIpAddress=1.2.3.4;_pp;_since=0;_expand:(instanceId,tags)' ; # now make the same request with _meta and select the ltime and stime # use data . publicIpAddress and sub field selectors data :( instanceId , tags ): curl 'http://localhost:8080/edda/api/v2/view/instances;data.publicIpAddress=1.2.3.4;_pp;_since=0;_expand;_meta:(stime,ltime,data:(instanceId,tags))' ; _pp \u00b6 This will pretty print the response. Along with beautifying the format to make it readable, it will also translate all the timestamps to more readable YYYY-MM-DDTHH:mm:ss.SSSZ time format. Note that the jq CLI tool can be used to provide a similar capability, except that it will not translate timestamps. # without pretty-print curl \"http://localhost:8080/edda/api/v2/aws/volumes/vol-0123456789\" # with pretty-print curl \"http://localhost:8080/edda/api/v2/aws/volumes/vol-0123456789;_pp\" _since \u00b6 _since is the start of a time range. If _until is not also specified, then the time range ends at \"now\". When _since is added to a request, it will show you the most recent revision of all resources that were valid at some point in that time range. Note that _since does not show you documents \"modified since\"; it will show any document that was valid during the time frame, even it that document had no revisions during the period. If you want to see only documents that were modified, use _updated along with _since . If you want to see all the documents alive in a time frame, then use _all with _since , otherwise it will only show you the most recent document found for each resource. # set the base url export EDDA = http : // localhost : 8080 # show the instance that has an EIP curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4 \" # show all instances that have ever had an EIP curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4;_since=0 \" # show all instances that have had an EIP since June 10 th curl \" $EDDA/api/v2view/instances;publicIpAddress=1.2.3.4;_since=1339286400000 \" # show all instances that had an EIP from June 10 th to June 15 th curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4;_since=1339286400000;_until=1339718400000 \" # see all revisions that had an EIP from June 10 th to June 15 th ( and select only id , and stime ) curl \" $EDDA/api/v2/view/instances;data.publicIpAddress=1.2.3.4;_since=1339286400000;_until=1339718400000;_all;_meta:(stime,id) \" # see list of all instances that changed on Jun 11 th between 10 : 00 and 10 : 01 am : curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" # you can use jshon to turn that list into something processable by the shell curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" | jshon - a - u # and a quick loop will show you all the changes curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" \\ | jshon - a - u \\ | while read instance ; do \\ curl \" $EDDA/api/v2/view/instances/$instance;_since=1339408800000;_until=1339408860000;_all;_diff=2 \" ; \\ done _until \u00b6 The value of this parameter is a timestamp, in milliseconds. This is the end of a time range started by _since . See the above documentation of _since for examples. _updated \u00b6 This will change the behavior from showing any valid documents in a time range to only showing documents that have been modified in a time range. You can implement \"if modified since\" logic with this to see only changed resources since the last time you polled (useful for periodic local cache updates). See an example in _since . Field Selectors \u00b6 Field Selectors can be used to restrict the data returned, and use matrix arguments to filter the data returned in cases where the resource id is not available or desired. Field Selectors syntax must always go at the end of the URI, it follows the form of: :( key , key :( subkey , subkey )) Here is an example that filters an AutoScalingGroup to only show the ASG name, instanceIds, and health status: # set the base url export ASGS = \"http://localhost:8080/edda/api/v2/aws/autoScalingGroups/edda-v123\" # filter the results to the specified fields curl \" $ASGS ;_pp:(autoScalingGroupName,instances:(instanceId,lifecycleState))\" { \"autoScalingGroupName\" : \"edda-v123\" , \"instances\" : [ { \"instanceId\" : \"i-0123456789\" , \"lifecycleState\" : \"InService\" }, { \"instanceId\" : \"i-012345678a\" , \"lifecycleState\" : \"InService\" }, { \"instanceId\" : \"i-012345678b\" , \"lifecycleState\" : \"InService\" } ] } Collection APIs \u00b6 /api/v2/aws \u00b6 All APIs under /api/v2/aws return the raw (JSON serialized) resources as the Amazon AWS APIs return. Collection Endpoints Notes addresses GET /api/v2/aws/addresses GET /api/v2/aws/addresses;_all GET /api/v2/aws/addresses/:name alarms GET /api/v2/aws/alarms GET /api/v2/aws/alarms;_all GET /api/v2/aws/alarms/:name autoScalingGroups GET /api/v2/aws/autoScalingGroups GET /api/v2/aws/autoScalingGroups;_all GET /api/v2/aws/autoScalingGroups/:name buckets GET /api/v2/aws/buckets GET /api/v2/aws/buckets;_all GET /api/v2/aws/buckets/:name databases GET /api/v2/aws/databases GET /api/v2/aws/databases;_all GET /api/v2/aws/databases/:name iamGroups GET /api/v2/aws/iamGroups GET /api/v2/aws/iamGroups;_all GET /api/v2/aws/iamGroups/:name iamRoles GET /api/v2/aws/iamRoles GET /api/v2/aws/iamRoles;_all GET /api/v2/aws/iamRoles/:name iamUsers GET /api/v2/aws/iamUsers GET /api/v2/aws/iamUsers;_all GET /api/v2/aws/iamUsers/:name iamVirtualMFADevices GET /api/v2/aws/iamVirtualMFADevices GET /api/v2/aws/iamVirtualMFADevices;_all GET /api/v2/aws/iamVirtualMFADevices/:name images GET /api/v2/aws/images GET /api/v2/aws/images;_all GET /api/v2/aws/images/:name instances GET /api/v2/aws/instances GET /api/v2/aws/instances;_all GET /api/v2/aws/instances/:name launchConfigurations GET /api/v2/aws/launchConfigurations GET /api/v2/aws/launchConfigurations;_all GET /api/v2/aws/launchConfigurations/:name loadBalancers GET /api/v2/aws/loadBalancers GET /api/v2/aws/loadBalancers;_all GET /api/v2/aws/loadBalancers/:name To find information about instances behind a load balancer, see the /view/loadBalancerInstances api reservedInstances GET /api/v2/aws/reservedInstances GET /api/v2/aws/reservedInstances;_all GET /api/v2/aws/reservedInstances/:name scalingPolicies GET /api/v2/aws/scalingPolicies GET /api/v2/aws/scalingPolicies;_all GET /api/v2/aws/scalingPolicies/:name securityGroups GET /api/v2/aws/securityGroups GET /api/v2/aws/securityGroups;_all GET /api/v2/aws/securityGroups/:name snapshots GET /api/v2/aws/snapshots GET /api/v2/aws/snapshots;_all GET /api/v2/aws/snapshots/:name tags GET /api/v2/aws/tags GET /api/v2/aws/tags;_all GET /api/v2/aws/tags/:name The tags api is a bit special. There are no primary keys for tags, there is a unique tuple of the tag name, the resource id and the resource type. volumes GET /api/v2/aws/volumes GET /api/v2/aws/volumes;_all GET /api/v2/aws/volumes/:name /api/v2/group \u00b6 These collections are special and quite different, because they primarily deal with group memberships (i.e. instances that are members of AutoScalingGroups). There is no corresponding AWS API that contains all the details. Also we do not store complete history for these APIs. New document revisions are generated for history any time the membership changes, not when a particular member changes. If an instance change IP address, it will be captured and stored to the data store, however you cannot find out what the previous IP address was with this API, for that you would need to use /view/instances . Basic interesting details about each member are captured and stored, but for more information about the members you will need to use the particular member apis. An additional key added for each member is slot . Slots are arbitrary numbers ranging from 0 to the size of the group. The slot numbers are assigned to members as soon as they appear, and the slot ID will never change for a member. When membership changes (ie old instance dies, new instance becomes member) then the old slot id will be reassigned to the new member. This mechanism is primarily used within Netflix for our Monitoring systems, so they can efficiently shard the massive amounts of metric data they collect for each instance. When using time range Modifier Matrix Arguments, the historical members will be merged into a single resource and the \"end\" time will be set to the last time the group saw the member. Collection Endpoints Notes autoScalingGroups GET /api/v2/group/autoScalingGroups GET /api/v2/group/autoScalingGroups;_all GET /api/v2/group/autoScalingGroups/:name /api/v2/view \u00b6 The view APIs represent aspects of other APIs, to make the data more usable and accessible. The /view/instances collection is the most commonly used one, since /aws/instances really returns the EC2 reservations. Since the individual instance data is generally more useful for us, we pull apart the /aws/instances document and store the instance details separated in a /view API. As described by the AWS SDK DescribeInstances documentation: The ID of the instance's reservation. A reservation ID is created any time you launch an instance. A reservation ID has a one-to-one relationship with an instance launch request, but can be associated with more than one instance if you launch multiple instances using the same launch request. For example, if you launch one instance, you get one reservation ID. If you launch ten instances using the same launch request, you also get one reservation ID. The /view/simpleQueues API likewise does not correspond to a single AWS API, it is a merge of multiple API calls to make the data more useful. Collection Endpoints Notes instances GET /api/v2/view/instances GET /api/v2/view/instances;_all GET /api/v2/view/instances/:name The documents from this API are derived from the /aws/instances API, but split out to be individually accessible. loadBalancerInstances GET /api/v2/view/loadBalancerInstances GET /api/v2/view/loadBalancerInstances;_all GET /api/v2/view/loadBalancerInstances/:name The documents from this API do not directly correspond to any AWS API; it is generated based on several AWS API calls. simpleQueues GET /api/v2/view/simpleQueues GET /api/v2/view/simpleQueues;_all GET /api/v2/view/simpleQueues/:name The documents from this API do not directly correspond to any AWS API; it is generated based on several AWS API calls. The Approximate* attributes are changing constantly, so Edda will not generate document revisions every time the values of an Approximate* key changes. However a change to any other attribute will generate a new document revision.","title":"REST API"},{"location":"rest-api/#rest-api","text":"","title":"REST API"},{"location":"rest-api/#introduction","text":"Resources can be fetched using HTTP GET requests. The output will always be JSON (or JSONP if _callback is used). In many cases the results of the GET's will be identical to an equivalent API call to the AWS service, however Edda will preserve cached copies of the API calls so users can query what the resource looked like at a specific time, or can quickly scan through all changes to a resource. Using Matrix Arguments you can find specific resources and with Field Selectors you can extract just the data elements you are interested.","title":"Introduction"},{"location":"rest-api/#general","text":"All APIs might return an error. There will be a non 200 HTTP status code returned with content formatted as: { \"code\" : 404 , \"message\" : \"not found\" }","title":"General"},{"location":"rest-api/#select-matrix-arguments","text":"You can use matrix arguments to query for specific resources. The argument name should map to the location in the document with a . character separating hierarchy levels. Given the following AWS AutoScalingGroup document structure: { \"launchConfigurationName\" : \"edda-201106231306\" , \"instances\" : [ { \"launchConfigurationName\" : \"edda-201106231306\" , \"instanceId\" : \"i-0123456789\" , \"lifecycleState\" : \"InService\" , \"availabilityZone\" : \"us-east-1d\" , \"healthStatus\" : \"Healthy\" } ], \"availabilityZones\" : [ \"us-east-1c\" , \"us-east-1d\" , \"us-east-1e\" ], \"autoScalingGroupName\" : \"edda\" } You could match it with these any of these queries: # set the base url export ASGS = \"http://localhost:8080/edda/api/v2/aws/autoScalingGroups\" # find an asg with a launch config curl \" $ASGS ;launchConfigurationName=edda-201106231306\" # find all asgs configured for a zone curl \" $ASGS ;availabilityZones=us-east-1e\" # find all asgs with at least one instance in a zone curl \" $ASGS ;instances.availabilityZone=us-east-1e\" Given this AWS Instance document structure: { \"instanceId\" : \"i-0123456789\" , \"publicIpAddress\" : \"1.2.3.4\" , \"tags\" : [ { \"key\" : \"aws:autoscaling:groupName\" , \"value\" : \"edda-v107\" } ], \"state\" : { \"name\" : \"terminated\" , \"code\" : 16 }, \"securityGroups\" : [ { \"groupId\" : \"sg-0123456789\" , \"groupName\" : \"corp\" } ], \"instanceType\" : \"m2.2xlarge\" , \"privateIpAddress\" : \"10.10.10.1\" , \"publicDnsName\" : \"ec2-1-2-3-4.compute-1.amazonaws.com\" , \"privateDnsName\" : \"ip-10-10-10-1.ec2.internal\" , \"imageId\" : \"ami-0123456789\" , \"placement\" : { \"tenancy\" : \"default\" , \"availabilityZone\" : \"us-east-1e\" , \"groupName\" : \"\" } } You could match it with any of these queries: # set the base url export INSTANCES = \"http://localhost:8080/edda/api/v2/view/instances\" # find an instance with a known publicIpAddress curl \" $INSTANCES ;publicIpAddress=1.2.3.4\" # find instances in a given state curl \" $INSTANCES ;state.name=terminated\" # find instances given a security group name curl \" $INSTANCES ;securityGroups.groupName=corp\" # find instances for a zone curl \" $INSTANCES ;placement.availabilityZone=us-east-1e\"","title":"Select Matrix Arguments"},{"location":"rest-api/#modifier-matrix-arguments","text":"All Modifier Matrix Arguments begin with a _ to try to avoid conflicts with the Select Matrix Arguments as described above.","title":"Modifier Matrix Arguments"},{"location":"rest-api/#_all","text":"By default, the APIs only return the most recent documents. If you need to see every document revision then then you can set _all . Typically this Modifier would be used with _diff or _meta . The _all parameter implies _expand . For example, you can use Field Selectors and _all to see all the state changes of a given instance, and use _meta to see when those changes happened: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_all;_pp;_meta:(stime,ltime,data:(state:(name)))'","title":"_all"},{"location":"rest-api/#_at","text":"The value of this parameter is a timestamp in milliseconds. You can use _at to view a document as it appeared in the past. If a document has changed (asg has new instances, instance has had eip attached) or is no longer valid (instance was terminated) then you can use _at to see the document as it was in the past. If you query for a document that is no longer valid you will get a 410 GONE error when fetched, and you can use _at to find the last seen copy: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_pp;_at=1340837213797'","title":"_at"},{"location":"rest-api/#_callback","text":"The value of this parameter is the name of the callback. This feature is used to provide a jsonp callback. The response content-type will be set to application/javascript and the content will be wrapped with the provided callback name. curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_pp;_at=1340837213797;_callback=mycallback'","title":"_callback"},{"location":"rest-api/#_diff","text":"The value of this parameter is an integer representing the number of lines of context you wish to see. _diff can be used to get a unified diff when several revisions of a document are found. This is typically used with _all , _since , _until and _limit . You can pass a value with the _diff argument as the number of lines of context. If you want the full document, leave a blank value for _diff . For example, to see the changes of a securityGroup over a given time range: curl \"http://localhost:8080/edda/api/v2/aws/securityGroups/sg-0123456789;_since=1340398800000;_until=1340402400000;_all;_diff=0\" To see the diffs in the last 4 revisions of an instance: curl 'http://localhost:8080/edda/api/v2/view/instances/i-0123456789;_diff=0;_all;_limit=4'","title":"_diff"},{"location":"rest-api/#_expand","text":"By default, when you get a collection without specifying a resource id, you will receive an index listing that contains only get the resource names. If you want to see the full details of each resource in the list, add the _expand parameter: # index listing curl 'http://localhost:8080/edda/api/v2/view/instances;_limit=2;_pp' # expanded curl 'http://localhost:8080/edda/api/v2/view/instances;_limit=2;_pp;_expand'","title":"_expand"},{"location":"rest-api/#_limit","text":"The value of this parameter is an integer. Any time a list is returned, you can restrict the quantity returned with _limit . It is frequently used with _all to see the last N revisions of a document. See the usage in _diff for an example use case.","title":"_limit"},{"location":"rest-api/#_live","text":"This option should rarely be used. Edda is built on top of a MongoDB datastore, but there is some in memory caching in the application servers. There is a possibility for the caches to be out of sync for brief period of time (cache is refreshed every 60s). If variation in the GET responses cannot be tolerated, then you can use _live to direct the queries directly to the MongoDB datastore.","title":"_live"},{"location":"rest-api/#_meta","text":"Edda collects some metadata for the documents it stores. If you use the _meta Modifier then the related metadata will be returned along the document. Here are the keys you will see: stime : Timestamp that Edda detected the document modification. ltime : Timestamp for when the document was last valid. mtime : Timestamp of when meta data was modified; it is typically the same as the stime . ctime : Either the create time of the document, or, if the the document has no create or start time available, then it will be the first time Edda saw the document. tags : Map of key-value pairs that are used for internal Edda mappings. id : Primary identifier for the document (instanceId, autoScalingGroupName, etc). data : The document as stored. _id : Internal primary key, formatted as id|stime , which isused by MongoDB to track the revisions. When using _meta with Select Matrix Arguments or Field Selectors, the document root changes and you will need to modify parameter names to match (i.e. add a data. prefix when you want to filter results with _meta and Select Matrix Arguments). # find all instances that have ever had an IP and print the instance ids and the tags : curl 'http://localhost:8080/edda/api/v2/view/instances;publicIpAddress=1.2.3.4;_pp;_since=0;_expand:(instanceId,tags)' ; # now make the same request with _meta and select the ltime and stime # use data . publicIpAddress and sub field selectors data :( instanceId , tags ): curl 'http://localhost:8080/edda/api/v2/view/instances;data.publicIpAddress=1.2.3.4;_pp;_since=0;_expand;_meta:(stime,ltime,data:(instanceId,tags))' ;","title":"_meta"},{"location":"rest-api/#_pp","text":"This will pretty print the response. Along with beautifying the format to make it readable, it will also translate all the timestamps to more readable YYYY-MM-DDTHH:mm:ss.SSSZ time format. Note that the jq CLI tool can be used to provide a similar capability, except that it will not translate timestamps. # without pretty-print curl \"http://localhost:8080/edda/api/v2/aws/volumes/vol-0123456789\" # with pretty-print curl \"http://localhost:8080/edda/api/v2/aws/volumes/vol-0123456789;_pp\"","title":"_pp"},{"location":"rest-api/#_since","text":"_since is the start of a time range. If _until is not also specified, then the time range ends at \"now\". When _since is added to a request, it will show you the most recent revision of all resources that were valid at some point in that time range. Note that _since does not show you documents \"modified since\"; it will show any document that was valid during the time frame, even it that document had no revisions during the period. If you want to see only documents that were modified, use _updated along with _since . If you want to see all the documents alive in a time frame, then use _all with _since , otherwise it will only show you the most recent document found for each resource. # set the base url export EDDA = http : // localhost : 8080 # show the instance that has an EIP curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4 \" # show all instances that have ever had an EIP curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4;_since=0 \" # show all instances that have had an EIP since June 10 th curl \" $EDDA/api/v2view/instances;publicIpAddress=1.2.3.4;_since=1339286400000 \" # show all instances that had an EIP from June 10 th to June 15 th curl \" $EDDA/api/v2/view/instances;publicIpAddress=1.2.3.4;_since=1339286400000;_until=1339718400000 \" # see all revisions that had an EIP from June 10 th to June 15 th ( and select only id , and stime ) curl \" $EDDA/api/v2/view/instances;data.publicIpAddress=1.2.3.4;_since=1339286400000;_until=1339718400000;_all;_meta:(stime,id) \" # see list of all instances that changed on Jun 11 th between 10 : 00 and 10 : 01 am : curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" # you can use jshon to turn that list into something processable by the shell curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" | jshon - a - u # and a quick loop will show you all the changes curl \" $EDDA/api/v2/view/instances;_since=1339408800000;_until=1339408860000;_updated \" \\ | jshon - a - u \\ | while read instance ; do \\ curl \" $EDDA/api/v2/view/instances/$instance;_since=1339408800000;_until=1339408860000;_all;_diff=2 \" ; \\ done","title":"_since"},{"location":"rest-api/#_until","text":"The value of this parameter is a timestamp, in milliseconds. This is the end of a time range started by _since . See the above documentation of _since for examples.","title":"_until"},{"location":"rest-api/#_updated","text":"This will change the behavior from showing any valid documents in a time range to only showing documents that have been modified in a time range. You can implement \"if modified since\" logic with this to see only changed resources since the last time you polled (useful for periodic local cache updates). See an example in _since .","title":"_updated"},{"location":"rest-api/#field-selectors","text":"Field Selectors can be used to restrict the data returned, and use matrix arguments to filter the data returned in cases where the resource id is not available or desired. Field Selectors syntax must always go at the end of the URI, it follows the form of: :( key , key :( subkey , subkey )) Here is an example that filters an AutoScalingGroup to only show the ASG name, instanceIds, and health status: # set the base url export ASGS = \"http://localhost:8080/edda/api/v2/aws/autoScalingGroups/edda-v123\" # filter the results to the specified fields curl \" $ASGS ;_pp:(autoScalingGroupName,instances:(instanceId,lifecycleState))\" { \"autoScalingGroupName\" : \"edda-v123\" , \"instances\" : [ { \"instanceId\" : \"i-0123456789\" , \"lifecycleState\" : \"InService\" }, { \"instanceId\" : \"i-012345678a\" , \"lifecycleState\" : \"InService\" }, { \"instanceId\" : \"i-012345678b\" , \"lifecycleState\" : \"InService\" } ] }","title":"Field Selectors"},{"location":"rest-api/#collection-apis","text":"","title":"Collection APIs"},{"location":"rest-api/#apiv2aws","text":"All APIs under /api/v2/aws return the raw (JSON serialized) resources as the Amazon AWS APIs return. Collection Endpoints Notes addresses GET /api/v2/aws/addresses GET /api/v2/aws/addresses;_all GET /api/v2/aws/addresses/:name alarms GET /api/v2/aws/alarms GET /api/v2/aws/alarms;_all GET /api/v2/aws/alarms/:name autoScalingGroups GET /api/v2/aws/autoScalingGroups GET /api/v2/aws/autoScalingGroups;_all GET /api/v2/aws/autoScalingGroups/:name buckets GET /api/v2/aws/buckets GET /api/v2/aws/buckets;_all GET /api/v2/aws/buckets/:name databases GET /api/v2/aws/databases GET /api/v2/aws/databases;_all GET /api/v2/aws/databases/:name iamGroups GET /api/v2/aws/iamGroups GET /api/v2/aws/iamGroups;_all GET /api/v2/aws/iamGroups/:name iamRoles GET /api/v2/aws/iamRoles GET /api/v2/aws/iamRoles;_all GET /api/v2/aws/iamRoles/:name iamUsers GET /api/v2/aws/iamUsers GET /api/v2/aws/iamUsers;_all GET /api/v2/aws/iamUsers/:name iamVirtualMFADevices GET /api/v2/aws/iamVirtualMFADevices GET /api/v2/aws/iamVirtualMFADevices;_all GET /api/v2/aws/iamVirtualMFADevices/:name images GET /api/v2/aws/images GET /api/v2/aws/images;_all GET /api/v2/aws/images/:name instances GET /api/v2/aws/instances GET /api/v2/aws/instances;_all GET /api/v2/aws/instances/:name launchConfigurations GET /api/v2/aws/launchConfigurations GET /api/v2/aws/launchConfigurations;_all GET /api/v2/aws/launchConfigurations/:name loadBalancers GET /api/v2/aws/loadBalancers GET /api/v2/aws/loadBalancers;_all GET /api/v2/aws/loadBalancers/:name To find information about instances behind a load balancer, see the /view/loadBalancerInstances api reservedInstances GET /api/v2/aws/reservedInstances GET /api/v2/aws/reservedInstances;_all GET /api/v2/aws/reservedInstances/:name scalingPolicies GET /api/v2/aws/scalingPolicies GET /api/v2/aws/scalingPolicies;_all GET /api/v2/aws/scalingPolicies/:name securityGroups GET /api/v2/aws/securityGroups GET /api/v2/aws/securityGroups;_all GET /api/v2/aws/securityGroups/:name snapshots GET /api/v2/aws/snapshots GET /api/v2/aws/snapshots;_all GET /api/v2/aws/snapshots/:name tags GET /api/v2/aws/tags GET /api/v2/aws/tags;_all GET /api/v2/aws/tags/:name The tags api is a bit special. There are no primary keys for tags, there is a unique tuple of the tag name, the resource id and the resource type. volumes GET /api/v2/aws/volumes GET /api/v2/aws/volumes;_all GET /api/v2/aws/volumes/:name","title":"/api/v2/aws"},{"location":"rest-api/#apiv2group","text":"These collections are special and quite different, because they primarily deal with group memberships (i.e. instances that are members of AutoScalingGroups). There is no corresponding AWS API that contains all the details. Also we do not store complete history for these APIs. New document revisions are generated for history any time the membership changes, not when a particular member changes. If an instance change IP address, it will be captured and stored to the data store, however you cannot find out what the previous IP address was with this API, for that you would need to use /view/instances . Basic interesting details about each member are captured and stored, but for more information about the members you will need to use the particular member apis. An additional key added for each member is slot . Slots are arbitrary numbers ranging from 0 to the size of the group. The slot numbers are assigned to members as soon as they appear, and the slot ID will never change for a member. When membership changes (ie old instance dies, new instance becomes member) then the old slot id will be reassigned to the new member. This mechanism is primarily used within Netflix for our Monitoring systems, so they can efficiently shard the massive amounts of metric data they collect for each instance. When using time range Modifier Matrix Arguments, the historical members will be merged into a single resource and the \"end\" time will be set to the last time the group saw the member. Collection Endpoints Notes autoScalingGroups GET /api/v2/group/autoScalingGroups GET /api/v2/group/autoScalingGroups;_all GET /api/v2/group/autoScalingGroups/:name","title":"/api/v2/group"},{"location":"rest-api/#apiv2view","text":"The view APIs represent aspects of other APIs, to make the data more usable and accessible. The /view/instances collection is the most commonly used one, since /aws/instances really returns the EC2 reservations. Since the individual instance data is generally more useful for us, we pull apart the /aws/instances document and store the instance details separated in a /view API. As described by the AWS SDK DescribeInstances documentation: The ID of the instance's reservation. A reservation ID is created any time you launch an instance. A reservation ID has a one-to-one relationship with an instance launch request, but can be associated with more than one instance if you launch multiple instances using the same launch request. For example, if you launch one instance, you get one reservation ID. If you launch ten instances using the same launch request, you also get one reservation ID. The /view/simpleQueues API likewise does not correspond to a single AWS API, it is a merge of multiple API calls to make the data more useful. Collection Endpoints Notes instances GET /api/v2/view/instances GET /api/v2/view/instances;_all GET /api/v2/view/instances/:name The documents from this API are derived from the /aws/instances API, but split out to be individually accessible. loadBalancerInstances GET /api/v2/view/loadBalancerInstances GET /api/v2/view/loadBalancerInstances;_all GET /api/v2/view/loadBalancerInstances/:name The documents from this API do not directly correspond to any AWS API; it is generated based on several AWS API calls. simpleQueues GET /api/v2/view/simpleQueues GET /api/v2/view/simpleQueues;_all GET /api/v2/view/simpleQueues/:name The documents from this API do not directly correspond to any AWS API; it is generated based on several AWS API calls. The Approximate* attributes are changing constantly, so Edda will not generate document revisions every time the values of an Approximate* key changes. However a change to any other attribute will generate a new document revision.","title":"/api/v2/view"},{"location":"support/","text":"Submit bugs and feature requests to GitHub Issues . Join the Edda Google Group to ask questions or if you are interested in helping out.","title":"Support"}]}